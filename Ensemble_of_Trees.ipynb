{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble of Trees",
      "provenance": [],
      "authorship_tag": "ABX9TyNyuONDGQpRrsSGYQ5GcWu6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KyungdaePark/HongongMachine/blob/master/Ensemble_of_Trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5aAHC4HBW3Y"
      },
      "outputs": [],
      "source": [
        "# 앙상블 트리 中 랜덤 포레스트 기법\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "wine = pd.read_csv('http://bit.ly/wine_csv_data')\n",
        "data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n",
        "target = wine[['class']].to_numpy()\n",
        "train_input, test_input, train_target, test_target = train_test_split(\n",
        "    data, target, test_size = 0.2, random_state = 42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForestClassifier의 성능을 cross_validate로 교차검증 해보자\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_jobs = -1, random_state = 42)\n",
        "scores = cross_validate(rf, train_input, train_target,\n",
        "                        return_train_score = True, n_jobs = -1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score'])) # 기본 5-fold cv이므로 score는 5개가 나올거임. 그것들의 평균 np.mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY0JMXF3CHRf",
        "outputId": "06b9fecf-ce1c-4fe6-d51e-2000542dfcf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9973541965122431 0.8905151032797809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과를 보니 과대적합이 나옴.\n",
        "# 랜덤 포레스트는 결정 트리의 앙상블이기 때문에 DecisionTreeClassifier가 제공하는 모든 매개변수 (criterion, max_depth ...)를 모두 제공함.\n",
        "# 랜덤 포레스트가 사용한 특성 중요도를 출력해 보자.\n",
        "rf.fit(train_input, train_target)\n",
        "print(rf.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mn1cIYpzCsu3",
        "outputId": "9bbf7980-a3a1-4029-9cd3-00fb3ce5bfe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.23167441 0.50039841 0.26792718]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 결정 트리에서는 중요도가 0.1 0.8 0.1 이었음. 랜덤 포레스트는 특성을 랜덤하게 선택해 여러 특성들이 훈련에 기여할 기회를 갖게 해줌.\n",
        "# --> 과대적합을 막는데 도움이 됨"
      ],
      "metadata": {
        "id": "cPEhblzVDsJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForestClassifier에는 자체적으로 모델을 평가하는 기능이 있음.\n",
        "# 훈련 세트에서 사용하지 않은 남는 샘플(Out Of Bag)들을 이용해 자체 검증이 가능.\n",
        "rf = RandomForestClassifier(oob_score = True, n_jobs = -1, random_state = 42)\n",
        "rf.fit(train_input, train_target)\n",
        "print(rf.oob_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE5VNn7jEI7Q",
        "outputId": "6dd184a6-b08b-4822-a08b-3e3048725de3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8934000384837406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 교차 검증 결과 : \n",
        "print(np.mean(scores['test_score']))\n",
        "# 와 매우 비슷함."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZRvZfNuEeae",
        "outputId": "de97dcc9-2198-47dd-e20e-35aeca15c3e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8905151032797809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################\n",
        "# 다음은 엑스트라 트리. 엑스트라 트리는 랜덤 포레스트와 매우 비슷하게 작동함.\n",
        "# DecisionTreeClassifier의 매개변수 역시 동일하게 사용 가능함.\n",
        "# 랜덤 포레스트와의 차이라면 훈련/테스트 세트를 만들때 부트스트랩 샘플을 사용하지 않음. 즉 결정트리를 만들때 모든 훈련 세트를 사용함.\n",
        "# 대신 노드 분할 시 최적의 분할을 찾지 않고 무작위로 분할함.\n",
        "# DecisionTreeClassifier의 매개변수 splitter=\"random\"인 트리가 엑스트라트리가 사용하는 결정트리임.\n",
        "# 장점 : 많은 트리를 앙상블하기 때문에 과대적합↓ 검증 세트의 점수↑ 속도↑\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "et = ExtraTreesClassifier(n_jobs = -1, random_state = 42)\n",
        "scores = cross_validate(et, train_input, train_target,\n",
        "                        return_train_score = True, n_jobs = -1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2JZ6wmfEqu1",
        "outputId": "7ba40a84-f743-4621-9389-02388b3491b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9974503966084433 0.8887848893166506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 특성 중요도 :\n",
        "et.fit(train_input, train_target)\n",
        "print(et.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cT9crcQMG78b",
        "outputId": "e13f5a44-63a0-4570-e514-dc89e654b98b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.20183568 0.52242907 0.27573525]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# 그레이디언트 부스팅 (gradient boosting)\n",
        "# 깊이가 얕은 결정트리를 이용함. 기본 깊이 3\n",
        "# 경사 하강법을 앙상블에 추가함\n",
        "# 경사 하강법은 모델의 가중치와 절편을 조금씩 바꾸는 과정\n",
        "# 경사 하강법은 조금씩 천천히 움직여야 함\n",
        "# 그래서 여기서도 깊이가 3인 얕은 트리를 사용한다.\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gb = GradientBoostingClassifier(random_state = 42)\n",
        "scores = cross_validate(gb, train_input, train_target, n_jobs = -1, return_train_score = True)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd39GjHkHHwf",
        "outputId": "8bbe83b7-86fd-446a-ef3d-21c4537625fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8881086892152563 0.8720430147331015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 과대적합이 거의 일어나지 않음. 결정트리의 개수를 늘려도 과대적합에 강하다.\n",
        "# 학습률을 증가시키고 트리의 개수를 늘리면 성능이 향상됨\n",
        "gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, random_state = 42) #learning_rate 의 기본값은 0.1\n",
        "scores = cross_validate(gb, train_input, train_target, return_train_score = True, n_jobs = -1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaNQoguXuQot",
        "outputId": "5383870c-a03a-42a8-bd0a-c78d5499945b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9464595437171814 0.8780082549788999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gb.fit(train_input, train_target)\n",
        "print(gb.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RyRM4Apun8E",
        "outputId": "e0f0dedb-21f8-46e3-c645-d2a9bcc79e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.15872278 0.68010884 0.16116839]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# subsample의 매개변수를 1보다 작게하면 훈련 세트의 일부만을 이용해 훈련함 \"확률적/미니배치 경사 하강법\"\n",
        "# 지금은 배치 경사 하강법"
      ],
      "metadata": {
        "id": "JdJkIYRBuyea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# 히스토그램 기반 그레디언트 부스팅 (Histogram-based Gradient Boosting)\n",
        "# 그레디언트 부스팅은 게속 트리를 추가하기 때문에 훈련속도가 느린데, 이를 보안한게 히스토그램 기반 그레디언트 부스팅임\n",
        "# 특성을 256개의 구간으로 나누어 최적의 분할을 매우 빠르게 처리함.\n",
        "\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "hgb = HistGradientBoostingClassifier(random_state = 42)\n",
        "scores = cross_validate(hgb, train_input ,train_target, return_train_score = True)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
        "\n",
        "# Gradient Boosting의 트리의 개수를 지정했던 n_estimators 대신 HistGradientBoostingClassifier는 max_iter 를 조정하여 부스팅 반복 횟수를 지정함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW8nXpJWu1lX",
        "outputId": "4ce3cdd1-2174-4493-9743-7fc1ecace7f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/experimental/enable_hist_gradient_boosting.py:17: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
            "  \"Since version 1.0, \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9321723946453317 0.8801241948619236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hgb.fit(train_input, train_target)\n",
        "# print(hgb.feature_importances_) ERROR\n",
        "\n",
        "# 특성 중요도를 알아보자\n",
        "# permutation_importance()를 사용함\n",
        "# 특성을 무작위로 섞어서 어떤 특성이 들어갔을 때 제일 성능이 좋은지를 판단해 그때의 특성을 출력함\n",
        "from sklearn.inspection import permutation_importance\n",
        "hgb.fit(train_input, train_target)\n",
        "result = permutation_importance(hgb, train_input, train_target, n_repeats = 10, random_state = 42, n_jobs=-1)\n",
        "print(result.importances_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXGxKWS0wGCH",
        "outputId": "a8de4ec2-e136-447f-c253-40d8ca460dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.08876275 0.23438522 0.08027708]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤 포레스트와 비슷한 비율이다.\n",
        "# rf = [0.23167441 0.50039841 0.26792718]\n",
        "# 테스트 세트에서의 특성 중요도 ?\n",
        "result = permutation_importance(hgb, test_input, test_target, n_repeats = 10, random_state = 42, n_jobs = -1)\n",
        "print(result.importances_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7odCRXpzjtf",
        "outputId": "ce459b52-97e2-440a-92c2-56aa564bbcfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.05969231 0.20238462 0.049     ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hgb.score(test_input, test_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flKcbk5c0PZQ",
        "outputId": "fe390b26-4cd8-4b58-8fc0-7c8d2e20d6ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8723076923076923"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "GvxxCuWL0XD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AtHeISi30T73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XlRI1se9weCo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}